{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["# CRNN Model\n","\n","### Data Preparation\n","The below code chunks imported data from kaggle and prepared the data for training."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T22:51:52.460539Z","iopub.status.busy":"2024-04-30T22:51:52.459242Z","iopub.status.idle":"2024-04-30T22:51:52.469225Z","shell.execute_reply":"2024-04-30T22:51:52.468276Z","shell.execute_reply.started":"2024-04-30T22:51:52.460501Z"},"trusted":true},"outputs":[],"source":["import polars as pl\n","import numpy as np\n","import pandas as pd\n","import lightgbm as lgb\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OrdinalEncoder,LabelEncoder\n","from sklearn.metrics import roc_auc_score \n","from sklearn.utils import shuffle\n","import warnings\n","from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n","from sklearn.base import BaseEstimator, RegressorMixin\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.feature_extraction import FeatureHasher\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from keras.src.layers import RNN\n","from tensorflow.keras import optimizers\n","import matplotlib.pyplot as plt\n","from keras.callbacks import EarlyStopping\n","\n","\n","dataPath = \"/kaggle/input/home-credit-credit-risk-model-stability/\""]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T22:48:19.678177Z","iopub.status.busy":"2024-04-30T22:48:19.677898Z","iopub.status.idle":"2024-04-30T22:48:19.686370Z","shell.execute_reply":"2024-04-30T22:48:19.685034Z","shell.execute_reply.started":"2024-04-30T22:48:19.678152Z"},"trusted":true},"outputs":[],"source":["def set_table_dtypes(df: pl.DataFrame) -> pl.DataFrame:\n","    # implement here all desired dtypes for tables\n","    # the following is just an example\n","    for col in df.columns:\n","        # last letter of column name will help you determine the type\n","        if col[-1] in (\"P\", \"A\"):\n","            df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n","\n","    return df\n","\n","def convert_strings(df: pd.DataFrame) -> pd.DataFrame:\n","    for col in df.columns:  \n","        if df[col].dtype.name in ['object', 'string']:\n","            df[col] = df[col].astype(\"string\").astype('category')\n","            current_categories = df[col].cat.categories\n","            new_categories = current_categories.to_list() + [\"Unknown\"]\n","            new_dtype = pd.CategoricalDtype(categories=new_categories, ordered=True)\n","            df[col] = df[col].astype(new_dtype)\n","    return df"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T22:48:19.688456Z","iopub.status.busy":"2024-04-30T22:48:19.687607Z","iopub.status.idle":"2024-04-30T22:48:36.212099Z","shell.execute_reply":"2024-04-30T22:48:36.211159Z","shell.execute_reply.started":"2024-04-30T22:48:19.688419Z"},"trusted":true},"outputs":[],"source":["train_basetable = pl.read_csv(dataPath + \"csv_files/train/train_base.csv\")\n","train_static = pl.concat(\n","    [\n","        pl.read_csv(dataPath + \"csv_files/train/train_static_0_0.csv\").pipe(set_table_dtypes),\n","        pl.read_csv(dataPath + \"csv_files/train/train_static_0_1.csv\").pipe(set_table_dtypes),\n","    ],\n","    how=\"vertical_relaxed\",\n",")\n","train_static_cb = pl.read_csv(dataPath + \"csv_files/train/train_static_cb_0.csv\").pipe(set_table_dtypes)\n","train_person_1 = pl.read_csv(dataPath + \"csv_files/train/train_person_1.csv\").pipe(set_table_dtypes) \n","train_credit_bureau_b_2 = pl.read_csv(dataPath + \"csv_files/train/train_credit_bureau_b_2.csv\").pipe(set_table_dtypes) "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T22:48:36.214734Z","iopub.status.busy":"2024-04-30T22:48:36.214399Z","iopub.status.idle":"2024-04-30T22:48:36.310501Z","shell.execute_reply":"2024-04-30T22:48:36.309057Z","shell.execute_reply.started":"2024-04-30T22:48:36.214703Z"},"trusted":true},"outputs":[],"source":["test_basetable = pl.read_csv(dataPath + \"csv_files/test/test_base.csv\")\n","test_static = pl.concat(\n","    [\n","        pl.read_csv(dataPath + \"csv_files/test/test_static_0_0.csv\").pipe(set_table_dtypes),\n","        pl.read_csv(dataPath + \"csv_files/test/test_static_0_1.csv\").pipe(set_table_dtypes),\n","        pl.read_csv(dataPath + \"csv_files/test/test_static_0_2.csv\").pipe(set_table_dtypes),\n","    ],\n","    how=\"vertical_relaxed\",\n",")\n","test_static_cb = pl.read_csv(dataPath + \"csv_files/test/test_static_cb_0.csv\").pipe(set_table_dtypes)\n","test_person_1 = pl.read_csv(dataPath + \"csv_files/test/test_person_1.csv\").pipe(set_table_dtypes) \n","test_credit_bureau_b_2 = pl.read_csv(dataPath + \"csv_files/test/test_credit_bureau_b_2.csv\").pipe(set_table_dtypes) "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T22:48:36.312757Z","iopub.status.busy":"2024-04-30T22:48:36.312387Z","iopub.status.idle":"2024-04-30T22:48:37.775496Z","shell.execute_reply":"2024-04-30T22:48:37.774550Z","shell.execute_reply.started":"2024-04-30T22:48:36.312722Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['amtinstpaidbefduel24m_4187115A', 'annuity_780A', 'annuitynextmonth_57A', 'avginstallast24m_3658937A', 'avglnamtstart24m_4525187A', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'credamount_770A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'disbursedcredamount_1113A', 'downpmt_116A', 'inittransactionamount_650A', 'lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M', 'lastapprcredamount_781A', 'lastcancelreason_561M', 'lastotherinc_902A', 'lastotherlnsexpense_631A', 'lastrejectcommoditycat_161M', 'lastrejectcommodtypec_5251769M', 'lastrejectcredamount_222A', 'lastrejectreason_759M', 'lastrejectreasonclient_4145040M', 'maininc_215A', 'maxannuity_159A', 'maxannuity_4075009A', 'maxdebt4_972A', 'maxinstallast24m_3658928A', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'maxpmtlast3m_4525190A', 'previouscontdistrict_112M', 'price_1097A', 'sumoutstandtotal_3546847A', 'sumoutstandtotalest_4493215A', 'totaldebt_9A', 'totalsettled_863A', 'totinstallast1m_4525188A']\n","['description_5085714M', 'education_1103M', 'education_88M', 'maritalst_385M', 'maritalst_893M', 'pmtaverage_3A', 'pmtaverage_4527227A', 'pmtaverage_4955615A', 'pmtssum_45A']\n"]}],"source":["# We need to use aggregation functions in tables with depth > 1, so tables that contain num_group1 column or \n","# also num_group2 column.\n","train_person_1_feats_1 = train_person_1.group_by(\"case_id\").agg(\n","    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n","    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n",")\n","\n","# Here num_group1=0 has special meaning, it is the person who applied for the loan.\n","train_person_1_feats_2 = train_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n","    pl.col(\"num_group1\") == 0\n",").drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})\n","\n","# Here we have num_goup1 and num_group2, so we need to aggregate again.\n","train_credit_bureau_b_2_feats = train_credit_bureau_b_2.group_by(\"case_id\").agg(\n","    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n","    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n",")\n","\n","# We will process in this examples only A-type and M-type columns, so we need to select them.\n","selected_static_cols = []\n","for col in train_static.columns:\n","    if col[-1] in (\"A\", \"M\"):\n","        selected_static_cols.append(col)\n","print(selected_static_cols)\n","\n","selected_static_cb_cols = []\n","for col in train_static_cb.columns:\n","    if col[-1] in (\"A\", \"M\"):\n","        selected_static_cb_cols.append(col)\n","print(selected_static_cb_cols)\n","\n","# Join all tables together.\n","data = train_basetable.join(\n","    train_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n",").join(\n","    train_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n",").join(\n","    train_person_1_feats_1, how=\"left\", on=\"case_id\"\n",").join(\n","    train_person_1_feats_2, how=\"left\", on=\"case_id\"\n",").join(\n","    train_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T22:48:37.776903Z","iopub.status.busy":"2024-04-30T22:48:37.776624Z","iopub.status.idle":"2024-04-30T22:48:37.788613Z","shell.execute_reply":"2024-04-30T22:48:37.787782Z","shell.execute_reply.started":"2024-04-30T22:48:37.776878Z"},"trusted":true},"outputs":[],"source":["test_person_1_feats_1 = test_person_1.group_by(\"case_id\").agg(\n","    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n","    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n",")\n","\n","test_person_1_feats_2 = test_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n","    pl.col(\"num_group1\") == 0\n",").drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})\n","\n","test_credit_bureau_b_2_feats = test_credit_bureau_b_2.group_by(\"case_id\").agg(\n","    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n","    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n",")\n","\n","data_submission = test_basetable.join(\n","    test_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n",").join(\n","    test_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n",").join(\n","    test_person_1_feats_1, how=\"left\", on=\"case_id\"\n",").join(\n","    test_person_1_feats_2, how=\"left\", on=\"case_id\"\n",").join(\n","    test_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T22:48:37.831948Z","iopub.status.busy":"2024-04-30T22:48:37.831640Z","iopub.status.idle":"2024-04-30T22:48:45.643348Z","shell.execute_reply":"2024-04-30T22:48:45.642540Z","shell.execute_reply.started":"2024-04-30T22:48:37.831922Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['amtinstpaidbefduel24m_4187115A', 'annuity_780A', 'annuitynextmonth_57A', 'avginstallast24m_3658937A', 'avglnamtstart24m_4525187A', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'credamount_770A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'disbursedcredamount_1113A', 'downpmt_116A', 'inittransactionamount_650A', 'lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M', 'lastapprcredamount_781A', 'lastcancelreason_561M', 'lastotherinc_902A', 'lastotherlnsexpense_631A', 'lastrejectcommoditycat_161M', 'lastrejectcommodtypec_5251769M', 'lastrejectcredamount_222A', 'lastrejectreason_759M', 'lastrejectreasonclient_4145040M', 'maininc_215A', 'maxannuity_159A', 'maxannuity_4075009A', 'maxdebt4_972A', 'maxinstallast24m_3658928A', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'maxpmtlast3m_4525190A', 'previouscontdistrict_112M', 'price_1097A', 'sumoutstandtotal_3546847A', 'sumoutstandtotalest_4493215A', 'totaldebt_9A', 'totalsettled_863A', 'totinstallast1m_4525188A', 'description_5085714M', 'education_1103M', 'education_88M', 'maritalst_385M', 'maritalst_893M', 'pmtaverage_3A', 'pmtaverage_4527227A', 'pmtaverage_4955615A', 'pmtssum_45A']\n"]}],"source":["case_ids = data[\"case_id\"].unique().shuffle(seed=1)\n","case_ids_train, case_ids_test = train_test_split(case_ids, train_size=0.6, random_state=1)\n","case_ids_valid, case_ids_test = train_test_split(case_ids_test, train_size=0.5, random_state=1)\n","\n","cols_pred = []\n","for col in data.columns:\n","    if col[-1].isupper() and col[:-1].islower():\n","        cols_pred.append(col)\n","\n","print(cols_pred)\n","\n","def from_polars_to_pandas(case_ids: pl.DataFrame) -> pl.DataFrame:\n","    return (\n","        data.filter(pl.col(\"case_id\").is_in(case_ids))[[\"case_id\", \"WEEK_NUM\", \"target\"]].to_pandas(),\n","        data.filter(pl.col(\"case_id\").is_in(case_ids))[cols_pred].to_pandas(),\n","        data.filter(pl.col(\"case_id\").is_in(case_ids))[\"target\"].to_pandas()\n","    )\n","\n","base_train, X_train, y_train = from_polars_to_pandas(case_ids_train)\n","base_valid, X_valid, y_valid = from_polars_to_pandas(case_ids_valid)\n","base_test, X_test, y_test = from_polars_to_pandas(case_ids_test)\n","\n","for df in [X_train, X_valid, X_test]:\n","    df = convert_strings(df)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T22:48:45.653238Z","iopub.status.busy":"2024-04-30T22:48:45.652906Z","iopub.status.idle":"2024-04-30T22:48:45.678612Z","shell.execute_reply":"2024-04-30T22:48:45.677598Z","shell.execute_reply.started":"2024-04-30T22:48:45.653211Z"},"trusted":true},"outputs":[],"source":["def gen_synthetic(x_data: pd.DataFrame, n: int, y_data: pd.Series, syn_type: int):\n","    \"\"\"\n","    x: X_train\n","    n: number of entries to generate\n","    y: y_train\n","    syn_type: class to generate, either 0 or 1\n","    \"\"\"\n","    \n","    \n","    x_data = x_data.assign(target=y_data.values)\n","    x_data = x_data[x_data['target'] == syn_type]\n","    x_data = x_data.drop('target', axis = 1)\n","    \n","    syn_y = []\n","\n","    syn_data = {}\n","    for col in x_data.columns.to_list():\n","        syn_data[col] = []\n","        data = x_data[col].value_counts().index.to_list()\n","        marginal = list(marginals(x_data, col).values())\n","        synthetic = np.random.choice(data, size=n, p=marginal)\n","        \n","        for syn_data_point in synthetic:\n","            syn_data[col].append(syn_data_point)\n","    \n","    for i in range(n):\n","        syn_y.append(1)\n","        \n","    syn_x = pd.DataFrame.from_dict(syn_data)\n","    syn_y = pd.Series(syn_y)\n","    return syn_x, syn_y\n","\n","def marginals(df: pd.DataFrame, col: str) -> {}:\n","    \"\"\"\n","    maps the probabilty of an occurence to the occurence\n","    \"\"\"\n","    data = df[col].value_counts()\n","    results = [x for x in data]\n","    labels = df[col].value_counts().index.to_list()\n","    syn_rep = {}\n","    \n","    for x in range(len(labels)):\n","        syn_rep[labels[x]] = max(0, results[x])\n","    \n","    total = sum(syn_rep.values())\n","    \n","    marginal = {}\n","    for x in labels:\n","        marginal[x] = syn_rep[x] / total\n","    return marginal\n","\n","def preprocess_data(x: pd.DataFrame, synthetic: bool, y: pd.DataFrame = [], synth_class: int = 1) -> pd.DataFrame:\n","    '''\n","    executes preprocessing as one function for ease of use\n","    \n","    @param\n","    x: data to preprocess\n","    y: target data for synthetic\n","    synthetic: whether or not to enhance data\n","    synth_class: which class to enhance\n","    '''\n","\n","    # FILL CATEGORICAL FEATURE NAN VALUES\n","    index = x.dtypes.index.to_list()\n","    categoricals = {}\n","        \n","    for i in range(len(x.dtypes)):\n","    \n","        if x.dtypes.iloc[i] == \"float32\" or x.dtypes.iloc[i] == \"float64\" or x.dtypes.iloc[i] == \"int32\":\n","            continue\n","        else:\n","            categoricals[index[i]] = str(x.dtypes.iloc[i])\n","\n","            data = x[index[i]].value_counts().index.to_list()\n","\n","            x = x.assign(**{index[i]:x[index[i]].fillna(data[0])})\n","            \n","    for col in x.columns:\n","        if x[col].isna().sum() > 0:\n","            x = x.assign(**{col:x[col].fillna(x[col].mean())})\n","            \n","    if synthetic == False:\n","\n","            # FEATURE TYPE CONVERSION\n","        float64_cols = list(x.select_dtypes(include='float64'))\n","\n","        # The same code again calling the columns\n","        x[float64_cols] = x[float64_cols].astype('float32')\n","\n","        encoder = OrdinalEncoder()\n","        encoder.fit(x[categoricals.keys()])\n","\n","        x[list(categoricals.keys())] = encoder.transform(x[list(categoricals.keys())])\n","        \n","        normalize_x = x.copy()\n","\n","        # apply normalization techniques \n","        for column in normalize_x.columns: \n","            normalize_x[column] = (normalize_x[column] - normalize_x[column].min()) / (normalize_x[column].max() - normalize_x[column].min())\n","\n","        return normalize_x\n","    \n","    syn_x, syn_y = gen_synthetic(x_data = x, n = len(x), y_data = y, syn_type = synth_class)\n","\n","    syn_X_train = pd.concat([syn_x, x])\n","    syn_y_train = pd.concat([syn_y, y])\n","\n","    # Merge and shuffle data\n","    syn_X_train['target'] = syn_y_train\n","    syn_X_train = syn_X_train.sample(frac = 1)\n","\n","    syn_y_train = syn_X_train['target']\n","    syn_X_train = syn_X_train.drop('target', axis = 1)\n","\n","    # FEATURE TYPE CONVERSION\n","    float64_cols = list(syn_X_train.select_dtypes(include='float64'))\n","\n","    # The same code again calling the columns\n","    syn_X_train[float64_cols] = syn_X_train[float64_cols].astype('float32')\n","\n","    encoder = OrdinalEncoder()\n","    encoder.fit(syn_X_train[categoricals.keys()])\n","\n","    syn_X_train[list(categoricals.keys())] = encoder.transform(syn_X_train[list(categoricals.keys())])\n","\n","    normalize_syn_x = syn_X_train.copy()\n","\n","    # apply normalization techniques \n","    for column in normalize_syn_x.columns: \n","        normalize_syn_x[column] = (normalize_syn_x[column] - normalize_syn_x[column].min()) / (normalize_syn_x[column].max() - normalize_syn_x[column].min())\n","\n","    return normalize_syn_x, syn_y_train\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T22:52:05.747196Z","iopub.status.busy":"2024-04-30T22:52:05.746354Z","iopub.status.idle":"2024-04-30T22:52:48.127537Z","shell.execute_reply":"2024-04-30T22:52:48.126369Z","shell.execute_reply.started":"2024-04-30T22:52:05.747162Z"},"trusted":true},"outputs":[],"source":["x_train, y_train = preprocess_data(X_train.head(int(len(X_train) / 2)), synthetic = True, y = y_train.head(int(len(y_train) / 2)))\n","x_valid, y_valid = preprocess_data(X_valid.head(int(len(X_valid) / 2)), synthetic = True, y = y_valid.head(int(len(y_valid) / 2)))"]},{"cell_type":"markdown","metadata":{},"source":["## Training CRNN\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T23:29:03.552389Z","iopub.status.busy":"2024-04-30T23:29:03.551988Z","iopub.status.idle":"2024-05-01T00:26:34.918264Z","shell.execute_reply":"2024-05-01T00:26:34.917284Z","shell.execute_reply.started":"2024-04-30T23:29:03.552356Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d_49 (Conv1D)          (None, 48, 64)            1152      \n","                                                                 \n"," conv1d_50 (Conv1D)          (None, 48, 64)            49216     \n","                                                                 \n"," conv1d_51 (Conv1D)          (None, 48, 128)           73856     \n","                                                                 \n"," max_pooling1d_18 (MaxPooli  (None, 48, 128)           0         \n"," ng1D)                                                           \n","                                                                 \n"," conv1d_52 (Conv1D)          (None, 48, 64)            98368     \n","                                                                 \n"," conv1d_53 (Conv1D)          (None, 48, 128)           73856     \n","                                                                 \n"," conv1d_54 (Conv1D)          (None, 48, 164)           147108    \n","                                                                 \n"," max_pooling1d_19 (MaxPooli  (None, 48, 164)           0         \n"," ng1D)                                                           \n","                                                                 \n"," simple_rnn_13 (SimpleRNN)   (None, 128)               37504     \n","                                                                 \n"," dropout_10 (Dropout)        (None, 128)               0         \n","                                                                 \n"," flatten_10 (Flatten)        (None, 128)               0         \n","                                                                 \n"," dense_20 (Dense)            (None, 1024)              132096    \n","                                                                 \n"," dense_21 (Dense)            (None, 1)                 1025      \n","                                                                 \n","=================================================================\n","Total params: 614181 (2.34 MB)\n","Trainable params: 614181 (2.34 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/100\n","14313/14313 [==============================] - 694s 48ms/step - loss: 0.3354 - accuracy: 0.8383 - val_loss: 0.8257 - val_accuracy: 0.6971\n","Epoch 2/100\n","14313/14313 [==============================] - 678s 47ms/step - loss: 0.1533 - accuracy: 0.9504 - val_loss: 0.6542 - val_accuracy: 0.7346\n","Epoch 3/100\n","14313/14313 [==============================] - 687s 48ms/step - loss: 0.1580 - accuracy: 0.9485 - val_loss: 0.3546 - val_accuracy: 0.8415\n","Epoch 4/100\n","14313/14313 [==============================] - 717s 50ms/step - loss: 0.1583 - accuracy: 0.9489 - val_loss: 0.6911 - val_accuracy: 0.6794\n","Epoch 5/100\n","14313/14313 [==============================] - 674s 47ms/step - loss: 0.1703 - accuracy: 0.9443 - val_loss: 0.4146 - val_accuracy: 0.8131\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from keras.src.layers import RNN\n","from tensorflow.keras import optimizers\n","import matplotlib.pyplot as plt\n","from keras.callbacks import EarlyStopping\n","\n","early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n","\n","lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate = 0.00001,\n","    decay_steps=2000,\n","    decay_rate=0.97,\n","    staircase=True)\n","\n","cnn = models.Sequential([\n","    layers.Conv1D(filters = 64, kernel_size = 17, activation='relu', padding = 'same', input_shape=(48, 1)),\n","    layers.Conv1D(filters = 64, kernel_size = 12, activation='relu', padding = 'same'),\n","    layers.Conv1D(filters = 128, kernel_size = 9, activation='relu', padding = 'same'),\n","    layers.MaxPooling1D(1, padding = 'same'),\n","    layers.Conv1D(filters = 64, kernel_size = 12, activation='relu', padding = 'same'),\n","    layers.Conv1D(filters = 128, kernel_size = 9, activation='relu', padding = 'same'),\n","    layers.Conv1D(filters = 164, kernel_size = 7, activation='relu', padding = 'same'),\n","    layers.MaxPooling1D(1, padding = 'same'),\n","    layers.SimpleRNN(128),\n","    layers.Dropout(.5),\n","    layers.Flatten(),\n","    layers.Dense(1024, activation='sigmoid'),\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","cnn.summary()\n","\n","\n","#refer to https://www.tensorflow.org/tutorials/keras/classification tutorial to check on how to use compile function\n","cnn.compile(optimizer='rmsprop', loss = 'binary_crossentropy', metrics=['accuracy'])\n","\n","# This will start the training and save each epoch output in the history list.\n","history_cnn = cnn.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_valid, y_valid), callbacks=[early_stopping])"]},{"cell_type":"markdown","metadata":{},"source":["Evaluation with AUC and then comparison with the stability metric is shown below."]},{"cell_type":"markdown","metadata":{},"source":["## Submission\n","\n","Scoring the submission dataset is below, we need to take care of new categories. Then we save the score as a last step. "]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-05-01T00:34:53.965406Z","iopub.status.busy":"2024-05-01T00:34:53.965034Z","iopub.status.idle":"2024-05-01T00:34:57.993722Z","shell.execute_reply":"2024-05-01T00:34:57.992941Z","shell.execute_reply.started":"2024-05-01T00:34:53.965366Z"},"trusted":true},"outputs":[],"source":["x_test = preprocess_data(X_test, False)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-05-01T00:35:14.278263Z","iopub.status.busy":"2024-05-01T00:35:14.277894Z","iopub.status.idle":"2024-05-01T00:36:18.529056Z","shell.execute_reply":"2024-05-01T00:36:18.528090Z","shell.execute_reply.started":"2024-05-01T00:35:14.278232Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["9542/9542 [==============================] - 58s 6ms/step\n"]},{"data":{"text/plain":["array([[0.2834317 ],\n","       [0.9309298 ],\n","       [0.43703723],\n","       ...,\n","       [0.03853424],\n","       [0.7353629 ],\n","       [0.60622114]], dtype=float32)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["cnn.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-05-01T00:33:12.766920Z","iopub.status.busy":"2024-05-01T00:33:12.766507Z","iopub.status.idle":"2024-05-01T00:33:13.426155Z","shell.execute_reply":"2024-05-01T00:33:13.425271Z","shell.execute_reply.started":"2024-05-01T00:33:12.766885Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 444ms/step\n"]}],"source":["X_submission = data_submission[cols_pred].to_pandas()\n","X_submission = convert_strings(X_submission)\n","categorical_cols = X_train.select_dtypes(include=['category']).columns\n","\n","for col in categorical_cols:\n","    train_categories = set(X_train[col].cat.categories)\n","    submission_categories = set(X_submission[col].cat.categories)\n","    new_categories = submission_categories - train_categories\n","    X_submission.loc[X_submission[col].isin(new_categories), col] = \"Unknown\"\n","    new_dtype = pd.CategoricalDtype(categories=train_categories, ordered=True)\n","    X_train[col] = X_train[col].astype(new_dtype)\n","    X_submission[col] = X_submission[col].astype(new_dtype)\n","\n"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-05-01T00:39:34.873273Z","iopub.status.busy":"2024-05-01T00:39:34.872581Z","iopub.status.idle":"2024-05-01T00:39:34.972853Z","shell.execute_reply":"2024-05-01T00:39:34.972101Z","shell.execute_reply.started":"2024-05-01T00:39:34.873242Z"},"trusted":true},"outputs":[],"source":["x_submission = preprocess_data(X_submission, False).fillna(0)\n"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-05-01T00:42:38.951697Z","iopub.status.busy":"2024-05-01T00:42:38.950738Z","iopub.status.idle":"2024-05-01T00:42:39.046331Z","shell.execute_reply":"2024-05-01T00:42:39.045153Z","shell.execute_reply.started":"2024-05-01T00:42:38.951658Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 32ms/step\n"]}],"source":["y_submission_pred = cnn.predict(x_submission)\n","submission_pred = []\n","\n","for y in y_submission_pred:\n","    submission_pred.append(y[0])\n","    "]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-05-01T00:42:54.184244Z","iopub.status.busy":"2024-05-01T00:42:54.183316Z","iopub.status.idle":"2024-05-01T00:42:54.195098Z","shell.execute_reply":"2024-05-01T00:42:54.194004Z","shell.execute_reply.started":"2024-05-01T00:42:54.184200Z"},"trusted":true},"outputs":[],"source":["submission = pd.DataFrame({\n","    \"case_id\": data_submission[\"case_id\"].to_numpy(),\n","    \"score\": submission_pred\n","}).set_index('case_id')\n","submission.to_csv(\"./submission.csv\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7493015,"sourceId":50160,"sourceType":"competition"}],"dockerImageVersionId":30635,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
